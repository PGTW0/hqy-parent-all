logging:
  config: classpath:logback.xml

server:
  port: 8205

spring:
  application:
    name: transaction-order-service
  profiles:
    active: dev
  cloud:
    nacos:
      config:
        server-addr: 120.76.65.160:8848
        file-extension: yaml
        namespace: 9cd8de3b-030a-49f1-9256-f04de35cdb9e
        group: DEV_GROUP
        extension-configs[0]:
          data-id: redis-config.yaml
          group: DEV_GROUP
          refresh: true
        extension-configs[1]:
          data-id: rabbitmq-config.yaml
          group: DEV_GROUP
          refresh: true
        extension-configs[2]:
          data-id: seata-config.yaml
          group: DEV_GROUP
          refresh: true
      discovery:
        ephemeral: true # false为永久实例，true表示临时实例
        namespace: 9cd8de3b-030a-49f1-9256-f04de35cdb9e
        server-addr: 120.76.65.160:8848
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource            # 当前数据源操作类型
    driver-class-name: org.gjt.mm.mysql.Driver              # mysql驱动包 com.mysql.jdbc.Driver
    url: jdbc:mysql://120.76.65.160:3306/transaction_order?useUnicode=true&characterEncoding=utf-8&useSSL=false
    username: root
    password: hongqy@2021
  kafka:
    bootstrap-servers:
      - 47.106.168.100:9092
      - 47.106.168.100:9093
      - 106.55.173.37:9090
    producer:
      retries: 0
      acks: 1
      batch-size: 16384
      properties:
        linger:
          ms: 0 # 提交延时
      # 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
      # linger.ms为0表示每接收到一条消息就提交给kafka,这时候batch-size其实就没用了
      buffer-memory: 33554432 # 生产端缓冲区大小
      # Kafka提供的序列化和反序列化类
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      properties:
        group:
          id: defaultConsumerGroup  # 默认的消费组ID
        session.timeout.ms: 120000 # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
        request.timeout.ms: 120000 # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
      enable-auto-commit: true # 是否自动提交offset
      auto-commit-interval: 1000 # 提交offset延时(接收到消息后多久提交offset)
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset;
      # latest:重置为分区中最新的offset(消费分区中新产生的数据);
      # none:只要有一个分区不存在已提交的offset,就抛出异常;
      auto-offset-reset: latest
      # Kafka提供的序列化和反序列化类
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    # 消费端监听的topic不存在时，项目启动会报错(关掉)
    listener:
      missing-topics-fatal: false

mapper:
  mappers: com.hqy.base.BaseDao
  not-empty: false
  identity: mysql
mybatis:
  mapperLocations: classpath:mapper/*.xml
  configuration:
    map-underscore-to-camel-case: true

# Seata 配置项，对应 SeataProperties 类
seata:
  application-id: transaction-order-service
  tx-service-group: transaction-order-service
  service:
    vgroup-mapping:
      transaction-order-service: default



